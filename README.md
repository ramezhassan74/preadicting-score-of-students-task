ğŸ“˜ Student Scores Prediction Task
ğŸ§® Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø·Ù„Ø§Ø¨
ğŸ§  Objective | Ø§Ù„Ù‡Ø¯Ù

English:
The goal of this task is to predict studentsâ€™ scores based on the number of study hours using regression models.
Two models were used and compared:

Linear Regression

Lasso Regression

Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:
Ù‡Ø¯Ù Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù‡Ùˆ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø·Ù„Ø§Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø°Ø§ÙƒØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±.
ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆÙ…Ù‚Ø§Ø±Ù†Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠÙ†:

Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ (Linear Regression)

Ø§Ù†Ø­Ø¯Ø§Ø± Ù„Ø§Ø³Ùˆ (Lasso Regression)

ğŸ§¹ Data Preparation | ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

English:

Loaded a dataset with:

hours: number of study hours

score: student score

Cleaned the data by:

Removing zero or negative values

Removing outliers using z-score

Checking for missing values (none found)
After cleaning, 100 valid rows remained.

Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:

ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:

hours: Ø¹Ø¯Ø¯ Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ù…Ø°Ø§ÙƒØ±Ø©

score: Ø¯Ø±Ø¬Ø© Ø§Ù„Ø·Ø§Ù„Ø¨

ØªÙ…Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø¹Ù† Ø·Ø±ÙŠÙ‚:

Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø³Ø§Ù„Ø¨Ø© Ø£Ùˆ Ø§Ù„ØµÙØ±ÙŠØ©

Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… z-score

Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø©
Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙØŒ Ø§Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù Ø¹Ù„Ù‰ 100 ØµÙ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸ÙŠÙØ©.

âš™ï¸ Model Training | ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
ğŸ”¹ Linear Regression Model | Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ

English:
A simple linear regression model was trained:

ğ‘ 
ğ‘
ğ‘œ
ğ‘Ÿ
ğ‘’
=
ğ‘
0
+
ğ‘
1
Ã—
â„
ğ‘œ
ğ‘¢
ğ‘Ÿ
ğ‘ 
score=b0+b1Ã—hours

Performance:

MAE: 3.164

RMSE: 3.837

RÂ²: 0.733

Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:
ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø­Ø¯Ø§Ø± Ø®Ø·ÙŠ Ø¨Ø³ÙŠØ· ÙˆÙÙ‚ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©:

ğ‘ 
ğ‘
ğ‘œ
ğ‘Ÿ
ğ‘’
=
ğ‘
0
+
ğ‘
1
Ã—
â„
ğ‘œ
ğ‘¢
ğ‘Ÿ
ğ‘ 
score=b0+b1Ã—hours

Ø§Ù„Ù†ØªØ§Ø¦Ø¬:

Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù…Ø·Ù„Ù‚ (MAE): 3.164

Ø§Ù„Ø¬Ø°Ø± Ø§Ù„ØªØ±Ø¨ÙŠØ¹ÙŠ Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·Ø£ Ø§Ù„ØªØ±Ø¨ÙŠØ¹ÙŠ (RMSE): 3.837

Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ¯ (RÂ²): 0.733

ğŸ”¹ Lasso Regression Model | Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø­Ø¯Ø§Ø± Ù„Ø§Ø³Ùˆ

English:
Used a pipeline combining:

StandardScaler() for scaling

Lasso(alpha=0.1) for regularization

Performance:

MAE: 3.319

RMSE: 4.060

RÂ²: 0.701

Cross Validation (5-Fold): Avg RÂ² â‰ˆ 0.70 Â± 0.03

Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:
ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø§ÙŠØ¨Ù„Ø§ÙŠÙ† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:

StandardScaler() Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‚ÙŠÙ…

Lasso(alpha=0.1) Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªØ£Ø«ÙŠØ± Ø§Ù„Ø²Ø§Ø¦Ø¯ Ù„Ù„Ø®ØµØ§Ø¦Øµ (Regularization)

Ø§Ù„Ù†ØªØ§Ø¦Ø¬:

MAE: 3.319

RMSE: 4.060

RÂ²: 0.701

ØªÙ‚ÙŠÙŠÙ… K-Fold (Ø¨Ø®Ù…Ø³ ØªÙ‚Ø³ÙŠÙ…Ø§Øª): Ù…ØªÙˆØ³Ø· RÂ² â‰ˆ 0.70 Â± 0.03

ğŸ“Š Results & Analysis | Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„

English:

The Linear Regression model performed slightly better.

Lasso gave slightly lower accuracy but is more stable and helps prevent overfitting.

Both models confirmed a clear positive relationship between hours and scores.

Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:

Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ø£Ø¹Ø·Ù‰ Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰ Ù†Ø³Ø¨ÙŠÙ‹Ø§.

Ù†Ù…ÙˆØ°Ø¬ Ù„Ø§Ø³Ùˆ ÙƒØ§Ù†Øª Ø¯Ù‚ØªÙ‡ Ø£Ù‚Ù„ Ù‚Ù„ÙŠÙ„Ù‹Ø§ØŒ Ù„ÙƒÙ†Ù‡ Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ù‹Ø§ ÙˆÙŠÙ‚Ù„Ù„ Ø®Ø·Ø± Ø§Ù„Ù€ Overfitting.

ÙƒÙ„Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† Ø£Ø¸Ù‡Ø±Ø§ Ø¹Ù„Ø§Ù‚Ø© Ø·Ø±Ø¯ÙŠØ© ÙˆØ§Ø¶Ø­Ø© Ø¨ÙŠÙ† Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª ÙˆØ§Ù„Ø¯Ø±Ø¬Ø§Øª.

ğŸ§© Next Steps | Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©

English:

Try Polynomial Regression for potential non-linear patterns.

Add more features (e.g., difficulty level, study method).

Tune the alpha parameter in Lasso for optimization.

Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:

ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ (Polynomial Regression) Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª ØºÙŠØ± Ø§Ù„Ø®Ø·ÙŠØ©.

Ø¥Ø¶Ø§ÙØ© Ø®ØµØ§Ø¦Øµ Ø¬Ø¯ÙŠØ¯Ø© (Ù…Ø«Ù„ ØµØ¹ÙˆØ¨Ø© Ø§Ù„Ù…Ø§Ø¯Ø© Ø£Ùˆ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø°Ø§ÙƒØ±Ø©).

Ø¶Ø¨Ø· Ù‚ÙŠÙ…Ø© alpha ÙÙŠ Lasso Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø£Ø¯Ø§Ø¡.

ğŸ’» Technologies Used | Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©

Python ğŸ

pandas

numpy

scikit-learn

matplotlib / seaborn
